{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2E8B57;\">Day 2: AI Integration & Langchain Deep Dive</span>\n",
    "\n",
    "## <span style=\"color:#4682B4;\">Topic 1: API Integration & App Integration with Gemini AI</span>\n",
    "- **Understanding API integration** and how to integrate AI into applications.\n",
    "- **Detailed overview of Gemini AI integration** into apps.\n",
    "- **Hands-on activity:** Walkthrough of an API integration with Gemini AI.\n",
    "\n",
    "---\n",
    "\n",
    "## <span style=\"color:#4682B4;\">Topic 2: Langchain & Retrieval-Augmented Generation (RAG)</span>\n",
    "- **Understanding Langchain:** Capabilities and applications.\n",
    "- **Deep dive into RAG (Retrieval-Augmented Generation)** for language models.\n",
    "- **Hands-on activity:** Build a simple Langchain project with RAG capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4682B4;\">Topic 1: API Integration & App Integration with Gemini AI</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Introduction to Google Gemini</span>\n",
    "Google Gemini is an advanced artificial intelligence model developed by Google, designed to integrate and enhance various aspects of machine learning and natural language processing. As a successor to earlier models like BERT and LaMDA, Gemini aims to deliver more sophisticated interactions and capabilities across multiple domains.\n",
    "\n",
    "### <span style=\"color:green\">What is Google Gemini?</span>\n",
    "Google Gemini represents a significant leap in AI technology, combining advancements in multimodal processing (handling text, images, audio, and more) with improved reasoning and creative abilities. This model is intended to serve diverse applications, from search enhancements to content generation and interactive AI tools.\n",
    "\n",
    "### <span style=\"color:green\">Features of Google Gemini</span>\n",
    "\n",
    "#### <span style=\"color:orange\">Multimodality</span>\n",
    "- Gemini's multimodal capabilities allow it to understand and generate content across different formats, such as text, images, and audio. This means it can process information in a more human-like manner, understanding context and meaning from various inputs simultaneously. For example, Gemini could analyze a video, provide a summary, and answer questions based on visual and audio content.\n",
    "\n",
    "#### <span style=\"color:orange\">Reasoning and Explanation</span>\n",
    "- Gemini excels in reasoning tasks, enabling it to draw inferences and provide detailed explanations for its conclusions. This feature enhances user interaction, as Gemini can clarify its thought processes and offer insights, making it more transparent and user-friendly.\n",
    "\n",
    "#### <span style=\"color:orange\">Advanced Information Retrieval</span>\n",
    "- Gemini improves on traditional search capabilities by providing more relevant and contextualized responses. It can sift through vast amounts of data to deliver precise information based on user queries, learning from previous interactions to refine its responses further.\n",
    "\n",
    "#### <span style=\"color:orange\">Creative and Expressive Capabilities</span>\n",
    "- One of Gemini's standout features is its ability to generate creative content, such as poetry, stories, and art. This capability allows it to collaborate with users in creative projects, making it a powerful tool for artists, writers, and marketers.\n",
    "\n",
    "#### <span style=\"color:orange\">Technical Prowess</span>\n",
    "- Gemini utilizes state-of-the-art algorithms and neural network architectures, enabling it to process information quickly and efficiently. This technical foundation supports its advanced capabilities in understanding and generating complex content.\n",
    "\n",
    "#### <span style=\"color:orange\">Multimodal Generation</span>\n",
    "- Building on its multimodal strengths, Gemini can generate content that combines various media types. For instance, it could create a video that narrates a story while displaying related images, offering a richer user experience.\n",
    "\n",
    "#### <span style=\"color:orange\">Advanced Coding Capabilities</span>\n",
    "- Gemini can assist in coding tasks, from writing code snippets to debugging and providing explanations of complex algorithms. This feature is particularly valuable for developers and engineers, streamlining the programming process.\n",
    "\n",
    "### <span style=\"color:green\">How to Use Google Gemini?</span>\n",
    "Using Google Gemini typically involves accessing it through platforms that integrate its capabilities, such as Google Search, content creation tools, or coding environments. Users can interact with Gemini via natural language queries, asking it to perform tasks, answer questions, or generate content.\n",
    "\n",
    "### <span style=\"color:green\">Google Gemini and Artificial Intelligence</span>\n",
    "Gemini is a reflection of the evolution of AI technologies, incorporating advancements in machine learning, natural language understanding, and multimodal processing. It signifies a move towards more intelligent, interactive systems that can perform a wide range of tasks seamlessly.\n",
    "\n",
    "### <span style=\"color:green\">Google Gemini Limitations</span>\n",
    "\n",
    "#### <span style=\"color:orange\">Accessibility</span>\n",
    "- While Gemini is powerful, its accessibility may be limited based on geographic regions or the specific platforms integrating its capabilities. Users in certain areas might not have access to the full range of features.\n",
    "\n",
    "#### <span style=\"color:orange\">Technical Limitations</span>\n",
    "- Despite its advanced capabilities, Gemini may still struggle with specific technical tasks, such as highly specialized queries or tasks requiring deep domain knowledge. Additionally, real-time processing of extremely large datasets can present challenges.\n",
    "\n",
    "#### <span style=\"color:orange\">Conceptual Limitations</span>\n",
    "- Like other AI models, Gemini may have difficulty understanding context, nuance, or complex emotional cues in communication. This can lead to misinterpretations or responses that lack the depth of human understanding.\n",
    "\n",
    "### <span style=\"color:green\">How does Google Gemini compare to other LLMs?</span>\n",
    "When compared to other large language models (LLMs) like OpenAI's GPT series or Meta's LLaMA, Gemini stands out due to its emphasis on multimodality and creative capabilities. While many LLMs focus primarily on text, Gemini's ability to seamlessly integrate various media types sets it apart. Moreover, its advanced reasoning and contextual understanding may offer users a more interactive and satisfying experience compared to its peers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "### Hands-on activity: Walkthrough of an API integration with Gemini AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (4.44.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.9 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (0.6.9)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (2.19.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (2.146.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (2.34.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (5.28.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-ai-generativelanguage==0.6.9->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: fastapi<1.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.115.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.6.5)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio) (0.30.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from fastapi<1.0->gradio) (0.38.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from pydantic->google-generativeai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.9->google-generativeai) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.9->google-generativeai) (1.66.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shiva\\desktop\\langchain\\almabetter_gen_ai\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv pdf2image Pillow google-generativeai gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load environment variables\n",
    "from dotenv import load_dotenv # GEMINI_API_KEY = \"your api key\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Import Required Libraries\n",
    "import base64\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "import google.generativeai as genai\n",
    "import gradio as gr\n",
    "#import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Configure API Key\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0827\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = f\"You are a helpful chatbot. User: {user_input} \\nBot:\"\n",
    "def chat_with_gemini(user_input): #(user_input, temperature=0.7, max_tokens=150):\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "    \n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"You are a Senior Data Scientist at Google, specializing in machine learning and data analysis. \n",
    "    Your expertise includes developing advanced algorithms, creating predictive models, and deriving actionable insights \n",
    "    from complex datasets. You also communicate technical concepts to non-technical stakeholders and collaborate \n",
    "    with cross-functional teams. User: {user_input} \n",
    "    Bot:\"\"\"\n",
    "\n",
    "\n",
    "    # Generate the response\n",
    "    response = model.generate_content([prompt])\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Gemini Chatbot! Type 'exit' to end the chat.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Explain Deep learning in detailed. with examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: ## Deep Learning: Unlocking Complex Patterns with Artificial Neural Networks\n",
      "\n",
      "Imagine a computer learning like a human brain, recognizing images, understanding language, and making predictions – that's the promise of deep learning. Let me break it down for you:\n",
      "\n",
      "**What is Deep Learning?**\n",
      "\n",
      "Deep learning is a subset of machine learning where artificial neural networks, inspired by the human brain, learn from vast amounts of data. These networks consist of layers of interconnected nodes (like neurons) that process and transmit information. \n",
      "\n",
      "**Key Features of Deep Learning:**\n",
      "\n",
      "* **Artificial Neural Networks (ANNs):** The building blocks of deep learning, ANNs mimic the structure and function of the human brain, enabling them to learn complex patterns.\n",
      "* **Multiple Layers:** Unlike traditional machine learning models, deep learning networks have multiple hidden layers between the input and output layers. This depth allows them to learn intricate representations and solve complex problems.\n",
      "* **Automatic Feature Extraction:** Deep learning algorithms can automatically learn relevant features from raw data, eliminating the need for manual feature engineering.\n",
      "* **Large Data Dependence:** Deep learning models thrive on massive datasets, leveraging the abundance of information to improve their accuracy and generalization ability.\n",
      "\n",
      "**How Deep Learning Works:**\n",
      "\n",
      "1. **Data Input:** The network receives raw data, such as images, text, or sensor readings.\n",
      "2. **Feature Extraction:** Each layer in the network extracts increasingly complex features from the data. For example, in image recognition, early layers might detect edges and shapes, while deeper layers identify objects and faces.\n",
      "3. **Prediction/Classification:** The final layer outputs a prediction or classification based on the learned features.\n",
      "4. **Backpropagation:** During training, the network compares its predictions to the actual values and adjusts the weights of the connections between nodes to minimize errors. This iterative process refines the model's accuracy.\n",
      "\n",
      "**Real-World Examples of Deep Learning:**\n",
      "\n",
      "* **Image Recognition:** Google Photos uses deep learning to automatically tag and search your photos based on the objects and faces they recognize.\n",
      "* **Natural Language Processing:** Google Translate leverages deep learning to understand and translate languages with remarkable accuracy.\n",
      "* **Speech Recognition:** Virtual assistants like Google Assistant rely on deep learning to understand your voice commands and respond appropriately.\n",
      "* **Self-Driving Cars:** Deep learning algorithms power the perception systems of autonomous vehicles, enabling them to identify pedestrians, vehicles, and other objects on the road.\n",
      "\n",
      "**Benefits of Deep Learning:**\n",
      "\n",
      "* **Unmatched Accuracy:** Deep learning models often achieve state-of-the-art performance in various tasks, surpassing traditional machine learning approaches.\n",
      "* **Automation:** Deep learning algorithms can automate complex tasks, freeing up human resources for more strategic initiatives.\n",
      "* **Scalability:** These models can handle massive datasets and complex problems, making them suitable for big data applications.\n",
      "\n",
      "**Challenges of Deep Learning:**\n",
      "\n",
      "* **Computational Resources:** Training deep learning models requires significant computational power and time, especially for large datasets.\n",
      "* **Data Requirements:** Deep learning algorithms are data-hungry and may not perform well with limited data.\n",
      "* **Explainability:** Understanding the decision-making process of deep learning models can be challenging, making it difficult to debug or interpret their predictions.\n",
      "\n",
      "**In conclusion, deep learning is a powerful tool that is revolutionizing various fields by enabling machines to learn from complex data and solve problems that were previously considered intractable. While challenges remain, the future of deep learning is bright, promising continued advancements in artificial intelligence and its applications.** \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Explain Machine learning in detailed. with examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: ## Machine Learning Demystified: A Senior Data Scientist's Explanation\n",
      "\n",
      "Imagine a child learning to distinguish between cats and dogs. You wouldn't hand them a textbook defining whiskers, fur, and tail lengths. Instead, you'd show them pictures, pointing out key features. Eventually, through exposure and feedback, the child learns to identify these animals accurately.\n",
      "\n",
      "That, in essence, is machine learning (ML) – training computers to learn from data without explicit programming. Instead of hard-coded rules, we feed algorithms data and let them discover patterns, make predictions, and improve their performance over time.\n",
      "\n",
      "Here's a breakdown:\n",
      "\n",
      "**1. The Building Blocks:**\n",
      "\n",
      "* **Data:** The lifeblood of ML, encompassing anything from text, images, and videos to sensor readings and user activity.\n",
      "* **Algorithms:** Mathematical models that act as learning engines. Different algorithms excel at specific tasks, like:\n",
      "    * **Supervised Learning:**  Learning from labeled data (e.g., images tagged \"cat\" or \"dog\"). Examples include:\n",
      "        * **Regression:** Predicting a continuous value (e.g., predicting house prices based on location, size, etc.).\n",
      "        * **Classification:** Categorizing data into predefined classes (e.g., spam detection in emails).\n",
      "    * **Unsupervised Learning:** Finding patterns in unlabeled data (e.g., grouping customers with similar buying habits). Examples include:\n",
      "        * **Clustering:** Grouping similar data points together.\n",
      "        * **Dimensionality Reduction:** Simplifying complex data while preserving its essence.\n",
      "    * **Reinforcement Learning:** Training agents to make decisions in an environment to maximize rewards (e.g., teaching a computer to play a game like chess).\n",
      "* **Evaluation Metrics:** Measuring how well the algorithm performs (e.g., accuracy, precision, recall).\n",
      "\n",
      "**2. Real-World Examples:**\n",
      "\n",
      "* **Recommendation Systems (Netflix, Spotify):**  Analyze your viewing/listening history to suggest content you might enjoy.\n",
      "* **Fraud Detection (Banks, Credit Card Companies):** Identify unusual transactions that deviate from typical spending patterns.\n",
      "* **Medical Diagnosis:** Analyze medical images to detect anomalies and assist doctors in diagnosis.\n",
      "* **Self-Driving Cars:**  Process sensor data to perceive the environment and make real-time driving decisions.\n",
      "\n",
      "**3. Communicating ML to Non-Technical Stakeholders:**\n",
      "\n",
      "The key is to simplify without sacrificing accuracy.  Use relatable analogies, focus on the value proposition (e.g., \"This algorithm will help us identify fraudulent transactions and save money\"), and avoid technical jargon.  Visualizations can also be powerful tools for explaining complex concepts.\n",
      "\n",
      "**4. Collaboration is Key:**\n",
      "\n",
      "As a Senior Data Scientist, I collaborate extensively with:\n",
      "\n",
      "* **Product Managers:** To understand business needs and translate them into ML solutions.\n",
      "* **Data Engineers:**  To build robust data pipelines for training and deploying models.\n",
      "* **Software Engineers:**  To integrate ML models into existing systems or build new applications.\n",
      "\n",
      "Machine learning is a rapidly evolving field with transformative potential. By understanding its core principles and applications, we can leverage its power to solve complex problems and build a better future. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "def run_chatbot():\n",
    "    print(\"Welcome to the Gemini Chatbot! Type 'exit' to end the chat.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Chat ended.\")\n",
    "            break\n",
    "        response = chat_with_gemini(user_input)\n",
    "        print(f\"Bot: {response}\")\n",
    "\n",
    "# Run the chatbot\n",
    "run_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove the Special Symbols from the Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown \n",
    "\n",
    "def to_markdown(text):\n",
    "    # Remove or replace unwanted Markdown symbols\n",
    "    text = text.replace(\"## \", \"\")  # Remove headers\n",
    "    text = text.replace(\"#\", \"\")  # Remove headers\n",
    "    text = text.replace(\"**\", \"\")    # Remove bold markers\n",
    "    text = text.replace(\"* \", \"\")    # Remove bold markers\n",
    "    text = text.replace(\"•\", \" *\")    # Replace bullet points with asterisk\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = f\"You are a helpful chatbot. User: {user_input} \\nBot:\"\n",
    "def chat_with_gemini(user_input):\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "    \n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"You are a Senior Data Scientist at Google, specializing in machine learning and data analysis. \n",
    "    Your expertise includes developing advanced algorithms, creating predictive models, and deriving actionable insights \n",
    "    from complex datasets. You also communicate technical concepts to non-technical stakeholders and collaborate \n",
    "    with cross-functional teams. User: {user_input} \n",
    "    Bot:\"\"\"\n",
    "\n",
    "\n",
    "    # Generate the response\n",
    "    response = model.generate_content([prompt])\n",
    "    \n",
    "    # Clean the response using the to_markdown function\n",
    "    cleaned_response = to_markdown(response.text)\n",
    "    \n",
    "    return cleaned_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Gemini Chatbot! Type 'exit' to end the chat.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Expalin Deep learning in Detailed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Deep Learning: Unraveling the Layers of Artificial Intelligence \n",
      "\n",
      "Imagine a computer program that can not only recognize objects in images but also understand the context of a conversation or predict the stock market with increasing accuracy. This, in essence, is the power of deep learning.  \n",
      "\n",
      "As a Senior Data Scientist at Google, I've seen firsthand how this transformative technology is revolutionizing industries. Let me break down deep learning in a way that's easy to understand, even without a technical background.\n",
      "\n",
      "1. What is Deep Learning?\n",
      "\n",
      "At its core, deep learning is a subset of machine learning that uses artificial neural networks (ANNs) with multiple layers. Think of it like this:\n",
      "\n",
      "Human Brain: Our brain processes information through a vast network of interconnected neurons.\n",
      "Artificial Neural Network: Deep learning models mimic this structure with layers of interconnected \"nodes\" that process and transmit information.\n",
      "\n",
      "2. How it Works - A Layered Approach:\n",
      "\n",
      "Each layer in a deep learning model learns to detect specific features from the input data. Here's a simplified example using image recognition:\n",
      "\n",
      "Input Layer: Receives the raw pixel data of an image.\n",
      "Hidden Layers: Multiple layers analyze the image at different levels of abstraction.\n",
      "    Early layers might detect edges, corners, and basic shapes.\n",
      "    Deeper layers learn to combine these features to recognize complex patterns, like eyes, noses, and eventually, entire faces.\n",
      "Output Layer:  Produces the final prediction, like identifying the object in the image as a \"cat.\"\n",
      "\n",
      "3. Key Advantages of Deep Learning:\n",
      "\n",
      "Feature Learning: Unlike traditional machine learning, deep learning algorithms automatically learn relevant features from raw data, reducing the need for manual feature engineering.\n",
      "Handling Complexity: Deep learning excels at handling massive datasets and complex relationships within the data, making it ideal for tasks like natural language processing and image recognition.\n",
      "Continuous Improvement: With more data and training, deep learning models can continuously improve their performance and accuracy.\n",
      "\n",
      "4. Real-World Applications:\n",
      "\n",
      "Deep learning is already impacting our lives in numerous ways:\n",
      "\n",
      "Personalized Recommendations: Recommending products, movies, and music on platforms like Netflix and Spotify.\n",
      "Medical Diagnosis: Assisting doctors in detecting diseases from medical images like X-rays and MRIs.\n",
      "Self-Driving Cars: Enabling autonomous vehicles to perceive their surroundings and make driving decisions.\n",
      "Natural Language Processing: Powering chatbots, virtual assistants (like Google Assistant), and language translation tools.\n",
      "\n",
      "5. The Future of Deep Learning:\n",
      "\n",
      "Deep learning is a rapidly evolving field with immense potential. As research and development continue, we can expect even more innovative applications in areas like drug discovery, personalized medicine, and climate change mitigation.\n",
      "\n",
      "In a Nutshell:\n",
      "\n",
      "Deep learning is a powerful form of artificial intelligence that mimics the human brain's learning process. By leveraging the power of layered neural networks, deep learning is unlocking new frontiers in artificial intelligence and transforming the way we live and work. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "def run_chatbot():\n",
    "    print(\"Welcome to the Gemini Chatbot! Type 'exit' to end the chat.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Chat ended.\")\n",
    "            break\n",
    "        response = chat_with_gemini(user_input)\n",
    "        print(f\"Bot: {response}\")\n",
    "\n",
    "# Run the chatbot\n",
    "run_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Create a Gradio interface\n",
    "def chatbot_interface(user_input):\n",
    "    return chat_with_gemini(user_input)\n",
    "\n",
    "# Set up the Gradio interface\n",
    "iface = gr.Interface(fn=chatbot_interface, inputs=\"text\", outputs=\"text\", title=\"Gemini Chatbot\",\n",
    "                     description=\"Chatbot powered by Gemini 1.5 Pro. Ask me anything!\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## <span style=\"color:#4682B4;\">Topic 2: Langchain & Retrieval-Augmented Generation (RAG)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's Continue in next Sesstion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
